<!DOCTYPE html>
<html>

  <head>
    
    <title>Telepresence-ROI</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">

          <h1 id="project_title">Telepresence-ROI</h1>
          <h2 id="project_tagline">Hand gesture based Region marking for tele-support using Wearables</h2>

          
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h2 id="welcome-to-telepresence-roi">Welcome to Telepresence-ROI</h2>

<p>Wearable AR devices are being explored in many applications,  for obtaining real-time contextual  information  and  also  tele-assistance  from  remote sites.  Tele-assistance is useful in many industrial scenarios,  where  the on-field  operators  often  require  expertâ€™s  guidance for trouble shooting and touchless hand gestures are the most intuitive way to select the region of interest(ROI), for eg.to highlight the defective parts.  The selected region using freehand sketching gestures can be conveyed to the remote site.  We present a hand gestural interaction method to localise the ROI in First Person View(FPV). Novelty of the proposed method include (a) touch-less finger-based gesture recognition that runs on Android wearables including smartphones,  which in addition with frugal  modality  like <a href="https://vr.google.com/cardboard/">Google Cardboard</a> and <a href="http://wearality.com/">Wearality</a>,  can  be used as a wearable, (b) real-time performance achieved by  implementing  the  hand  gesture  recognition  module  on a smartphone and thus reducing the network latency.</p>

<h2 id="the-idea">The Idea</h2>
<p><img src="https://github.com/arc4224/AirGestures-ROI/blob/master/img/Setup.png" alt="Proposedmethod" /></p>







      </section>
    </div>

    



  </body>
</html>
